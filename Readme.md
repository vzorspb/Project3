Итоговая аттестация по курсу "Инженер данных"

Проект № 3.

Анализ логов

Общая задача: создать скрипт для формирования витрины на основе логов web-сайта.

Подробное описание задачи:

Разработать скрипт формирования витрины следующего содержания:
1.      Суррогатный ключ устройства
2.      Название устройства
3.      Количество пользователей
4.      Доля пользователей данного устройства от общего числа пользователей.
5.      Количество совершенных действий для данного устройства
6.      Доля совершенных действий с данного устройства, относительно других устройств
7.      Список из 5 самых популярных браузеров, используемых на данном устройстве различными пользователями, с указанием доли использования для данного браузера относительно остальных браузеров. 
8.      Количество ответов сервера отличных от 200 на данном устройстве
9.      Для каждого из ответов сервера, отличных от 200, сформировать поле, в котором будет содержаться количество ответов данного типа

Источники:

https://disk.yandex.ru/d/BsdiH3DMTHpPrw 

Предварительный анализ данных:
в полученном для обработки архиве содержатся 2 файла:
    итого 3,3G
    3,3G access.log   
    13M client_hostname.csv
Первый содержит логи WEB сервера за период с 22.01.2019 3:56 по 26.01.2019 20:29 объемом 3.3G
Второй список IP адресов клиентов с информацией о наличии обратной зоны на DNS сервере. (использовать не будем, т.к. в файле отсутствуют данные, необходимые для решения задачи)

Лог файл содержит данные за 5 дней 16 часов 33 минуты = 8193 мин.
Исходя из того, что в году у нас 525600 минуть, делаем предположение, что логи за год у нас заямут 211,7 Гб.

Попытка № 1 (неудачная)
   Для  решения задачи выберем следующий технологический стек: Python + PostgreSQL.
   Для парсинга user-agent будем использовать библиотеку https://pypi.org/project/user-agents/
   Запрос данных с групировкой по одному полю занимал более 15 минут.
   Дождаться завершения запроса, содержащего JOIN не удалось.
   
Попытка № 2 (удачная)
   Для  решения задачи выберем следующий технологический стек: Python + ClickHouse.
   Запрос данных с групировкой по одному полю занимал более 15 минут.
   
   Проект содержит 2 скрипта:
   1. Создает таблицу в базе данных ClickHouse и загружает туда Log дополняя нанными парсинга поля useragent
      Скрипт расположен:
      /src/clickhouse.py
   2. Формирует витрину в виде текстового файла в соответствии с заданием
      Скрипт расположен:
      /src/generate.py
      
      
Результат работы скриптов представлен ниже

