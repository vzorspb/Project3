Итоговая аттестация по курсу "Инженер данных"

Проект № 3.

Анализ логов

Общая задача: создать скрипт для формирования витрины на основе логов web-сайта.

Подробное описание задачи:

Разработать скрипт формирования витрины следующего содержания:
1.      Суррогатный ключ устройства
2.      Название устройства
3.      Количество пользователей
4.      Доля пользователей данного устройства от общего числа пользователей.
5.      Количество совершенных действий для данного устройства
6.      Доля совершенных действий с данного устройства, относительно других устройств
7.      Список из 5 самых популярных браузеров, используемых на данном устройстве различными пользователями, с указанием доли использования для данного браузера относительно остальных браузеров. 
8.      Количество ответов сервера отличных от 200 на данном устройстве
9.      Для каждого из ответов сервера, отличных от 200, сформировать поле, в котором будет содержаться количество ответов данного типа

Источники:

https://disk.yandex.ru/d/BsdiH3DMTHpPrw 

Предварительный анализ данных:
в полученном для обработки архиве содержатся 2 файла:
    итого 3,3G
    3,3G access.log   
    13M client_hostname.csv
Первый содержит логи WEB сервера за период с 22.01.2019 3:56 по 26.01.2019 20:29 объемом 3.3G
Второй список IP адресов клиентов с информацией о наличии обратной зоны на DNS сервере.

Лог файл содержит данные за 5 дней 16 часов 33 минуты = 8193
Исходя из того, что в году у нас 525600 минуть, делаем предположение, что логи за год у нас заямут 211,7 Гб.
В соответствии с приказом Минкульта обрабатываемые данные не относятся к документам постоянного хранения, то делаем экспертную оценку, что хранить информацию более 10 лет нам точно не придется.
Т.к. характеристики современного серверного оборудования позволяют производить обработку данного объема информации одним сервером => применение технологий распределенных вычислений нам не потребуется.


Для  решения задачи выберем следующий технологический стек: Python + PostgreSQL.
Для парсинга user-agent будем использовать библиотеку https://pypi.org/project/user-agents/

1. Скриптом initdb.sh создаем новую базу данных и структуру таблиц.

2. Запускаем
    python ./stc/data_load.py
    для парсинга и загрузки данных из файлов в базу данных
3. После того, как скрипт отработал проверяем содержимое файла ./access.err
   В него попадут строки, которые не удалось распарсить.
   Если такое произошло - под эти строки в data_load.py необходимо добавить дополнительное регулярное выражение
   
4. Проверяем, что за данные нам выдали, а именно насколько IP адреса в файле client_hostname.csv соответствуют данным в файле access.log
   Делаем это прогнав SQL запоос:
   select ip from logdb.public.httpdlog where not (BTRIM(ip) in (select BTRIM(ip) from logdb.public.client_hostname)) group by ip

